from google.colab import drive
import zipfile
drive.mount('/content/gdrive/')

my_zip = zipfile.ZipFile("/content/gdrive/MyDrive/final_project/Dataset.zip", 'r')
my_zip.extractall('/content/gdrive/MyDrive/final_project')


#함수불러오기
import cv2
import os
import numpy as np
import zipfile
import torch
import os,time
import torch.nn as nn
import torch.nn.functional as F


#Data_load
def image_load(img_path,height=128,width=128,bshort=False):
  #image total number
  img_names=os.listdir(img_path)

  if not bshort:
    img_num=len(img_names)
  else:
    img_num=10000

  print('img num:%d'%img_num)
  images=np.zeros((img_num,height,width,3),dtype=np.uint8)

  for it in range(img_num):
    images[it,:,:,:]=cv2.imread(img_path+'%s'%(img_names[it]))

  return images

def gt_load(gt_file):
  f=open(gt_file)
  lines=f.readLines()
  num_gt=len(lines)
  print('gt num:%d'%num_gt)

  gts=np.zeros(num_gt,dtype=np.int32)

  for it in range(num_gt):
    gts[it]=int(lines[it][:-1])-1 #1~200 -> 0~199 로 변환

  f.close()

  return gts

def mini_batch_image(train_img,train_gts,batch_size,crop_size=128):
  batch_img=np.zeros((batch_size,crop_size,crop_size,3),dtype=np.float32)
  batch_cls=np.zeros(batch_size,dtype=np.long)

  rand_num=np.random.randint(0,train_img.shape[0],batch_size)

  for it in range(batch_size):
    img=train_img[rand_num[it],:,:,:]

    #dataAug1. Flip
    rand_flip=np.random.normal(0,0,scale=1.0)
    if rand_flip<0:
      img=cv2.flip(img,1)

    #dataAug2. Crop
    crop_y=np.random.randint(0,img.shape[0]-crop_size-1)
    crop_x=np.random.randint(0,img.shape[1]-crop_size-1)
    img=img[crop_y:crop_y+crop_size,crop_x:crop_x+crop_size,:]

    batch_img[it,:,:,:]=(img/255.0*2.0)-1.0
    batch_gts[it]=train_gts[rand_num[it]]

  return batch_img,batch_gts


#Network
class residual_block(nn.Module):
  def __init__(self,c_in,c_out,bdown=False):
    super(residual_block,self).__init__()

    self.c_in=c_in
    self.c_out=c_out

    self.bdown=bdown
    if self.bdown:
      stride=2
    else:
      stride=1

    self.convs=nn.Sequential(nn.BatchNorm2d(c_in),
                             nn.ReLU(),
                             nn.Conv2d(c_in,c_out,kernel_size=(3,3),padding=1,stride=(stride,stride)),
                             nn.BatchNorm2d(c_out),
                             nn.ReLU(),
                             nn.Conv2d(c_out,kernel_size=(3,3),padding=1),
    )

    if self.c_in!=c_out:
      self.conv_db=nn.Conv2d(c_in,c_out,kernel_size=(1,1),stride=(stride,stride))
    
  def forward(self,x):
    y=x
    x=self.convs(x)

    if self.c_in!=self.c_out:
      y=self.conv_db(y)

    return (x+y)/np.sqrt(2.0)



class ResNet(nn.Module):
  def __init__(self,c_in=3,conv_ch=64,output_size=200):
    super(ResNet,self).__init__()
    self.ch=conv_ch

    self.conv=nn.Conv2d(c_in,self.ch,kernel_size=(7,7),padding=3,stride=(2,2))
    self.maxp=nn.MaxPool2d(kernel_size=(3,3),stride=(2,2))
    self.resblocks=nn.Sequential(residual_block(self.ch,self.ch),
                                 residual_block(self.ch,self.ch),

                                 residual_block(self.ch*2,self.ch,bdown=True),
                                 residual_block(self.ch*2,self.ch*2),

                                 residual_block(self.ch*2,self.ch*4,bdown=True),
                                 residual_block(self.ch*4,self.ch*4),

                                 residual_block(self.ch*4,self.ch*8,bdown=True),
                                 residual_block(self.ch*8,self.ch*8),

                                 nn.BatchNorm2d(8*self.ch),
                                 nn.ReLU(),
                                 )
    self.dr=nn.Dropout(p=0.2)
    self.fc=nn.Linear(8*self.ch,output_size)

  def forward(self,x):
    x=self.conv(x)
    x=self.maxp(x)
    x=self.resblocks(x)
    x=torch.mean(x,dim=(2,3))
    x=self.dr(x)
    x=self.fc(x)

    return x


#1. parameter setting
num_class=200
batch_size=64 #or32 교수님이 64추천
initial_lr=1e-2
max_iter=100000

save_name='Res18_SGD_b64'

model_save_path='./model/%s/'%save_name
model_saving_iter=5000
brestore=False
restore_iter=6000
if not brestore:
  restore_iter=0

DEVICE='cuda' if torch.cuda.is_available()else 'cpu'
print(DEVICE)


#2. data load
print('DATA LOAD')
train_images=image_load('/content/drive/MyDrive/final_project/train/')
train_gts=gt_load('/content/drive/MyDrive/final_project/test_gt_short.txt')

test_images=image_load('/content/drive/MyDrive/final_project/test/',bshort=True)
test_gts=gt_load('/content/drive/MyDrive/final_project/test_gt_short.txt')

print('DATA LOAD FINISH')

test_images=image_load()
test_gts=gt_load()

print('DATA LOAD FINISH')

#3. network build
model=ResNet().to(DEVICE)

if brestore:
  model.load_state_dict(torch.load(model_save_path+'model_%d.pt'%restore_iter))

#4.loss function and optimizer
loss=torch.nn.CrossEntropyLoss()
#optimizer=torch.optim.Adam(model.parameters(),lr=initial_lr,eps=1.0)  #교수님이 eps=1.0추천
optimizer=torch.optim.SGD(model.parameters(),lr=initial_lr,weight_decay=1e-4,momentum=0.9)

start_time=time.time()
for it in range(restore_iter,max_iter+1):
  optimizer.param_groups[0]['lr']=initial_lr-(it/max_iter)*initial_lr

  batch_img,batch_gts=mini_batch_image(train_images,train_gts,batch_size)
  batch_img=np.transpose(batch_img,(0,3,1,2))

  #training step
  model.train()
  optimizer.zero_grad()
  pred=model(torch.from_numpy(batch_img).to(DEVICE))
  gt_tensor=torch.tensor(batch_gts,dtype=torch.long).to(DEVICE)

  train_loss=loss(pred,gt_tensor)
  train_loss.backward()
  optimizer.step()

  if it%100==0:
    consume_time=time.time()-start_time
    print('iter : %d lr : %.5f   loss : %.5f  time : %.4f'%(it,optimizer.param_groups[0]['lr'],train_loss.item(),consume_time))
    start_time=time.time()

  if it%model_saving_iter==0 and it!=0:
    print('SAVING MODEL')
    if not os.path.isdir(model_save_path):
      os.makekirs(model_save_path)

    torch.save(model.state_dict(),model_save_path+"model_%d.pt"%it)
    print("SAVING MODEL FINISH")

    print("START TEST")
    model.eval()
    t1_count=0
    t5_count=0
    for itest in range(10000):
      test_img=test_images[itest:itest+1,:,:,:].astype(np.float32)
      test_img=(test_img/255.0*2.0)-1.0

      test_img=np.transpose(test_img,(0,3,1,2))
      with torch.no_grad():
        pred=model(torch.from_numpy(test_img).to(DEVICE))

      gt=test_gts[itest]

      pred=pred.cpu().numpy()
      pred=np.reshape(pred,num_class)

      #top5 accuracy
      for ik in range(5):
        max_index=np.argmax(pred)
        if int(gt)==int(max_index):
          t5_count+=1
          if ik==0:
            t1_count+=1
        pred[max_index]=-9999

    print('top1:%f   top5:%f \n'%(t1_count/10000*100,t5_count/10000*100))
    f=open('%s.txt'%save_name,'a+')
    f.write('top1:%f   top5:%f \n'%(t1_count/1000*100,t5_count/10000*100))
    f.close()
